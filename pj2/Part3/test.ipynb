{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import MyDataset\n",
    "from data_process import data_process, build_tag2id, build_word2id\n",
    "from model import Transformer_CRF\n",
    "from runner import Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10d8c9610>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Language = \"English\"\n",
    "# Language = \"Chinese\"\n",
    "param_num = 0\n",
    "model_param = {\"English0\": (256, 256), \"Chinese0\": (256, 256)}\n",
    "\n",
    "EPOCHS = 2\n",
    "EMBEDDING_DIM, HIDDEN_DIM = model_param[f\"{Language}{param_num}\"]\n",
    "BATCH_SIZE = 16\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"mps\"\n",
    "\n",
    "torch.manual_seed(3407)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_process(f\"../NER/{Language}\", \"test\")\n",
    "\n",
    "word2id, id2word = build_word2id(f\"../NER/{Language}/train.txt\")\n",
    "tag2id, id2tag = build_tag2id(f\"../NER/{Language}/tag.txt\")\n",
    "\n",
    "test_dataset = MyDataset(f\"../NER/{Language}/test.npz\", word2id, tag2id)\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    BATCH_SIZE,\n",
    "    pin_memory=False,\n",
    "    shuffle=False,\n",
    "    collate_fn=test_dataset.collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer_CRF(EMBEDDING_DIM, HIDDEN_DIM, word2id, tag2id, device)\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = Runner(model, optimizer, len(tag2id))\n",
    "runner.load_model(f\"{Language}{param_num}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 216/216 [03:35<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-PER     0.9115    0.5158    0.6588      1617\n",
      "       I-PER     0.9382    0.4991    0.6516      1156\n",
      "       B-ORG     0.8349    0.6026    0.7000      1661\n",
      "       I-ORG     0.8277    0.6443    0.7246       835\n",
      "       B-LOC     0.8503    0.8040    0.8265      1668\n",
      "       I-LOC     0.8258    0.5720    0.6759       257\n",
      "      B-MISC     0.8532    0.7037    0.7713       702\n",
      "      I-MISC     0.6394    0.6157    0.6274       216\n",
      "\n",
      "   micro avg     0.8554    0.6244    0.7219      8112\n",
      "   macro avg     0.8351    0.6197    0.7045      8112\n",
      "weighted avg     0.8634    0.6244    0.7169      8112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "from NER.check import check\n",
    "\n",
    "output_file = f\"output_{Language}.txt\"\n",
    "\n",
    "# 使用 torch.no_grad() 语句和打开文件的语句\n",
    "with torch.no_grad():\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        model.eval()\n",
    "        my_tags = []\n",
    "        real_tags = []\n",
    "        for sentence, _, sentence_len in tqdm(test_dataloader):\n",
    "            sentence = sentence.to(device)\n",
    "            sentence_len = sentence_len.to(device)\n",
    "            pred_tags = model(sentence, sentence_len, mode=\"eval\")\n",
    "            for sent, tags in zip(sentence, pred_tags):\n",
    "                for word_id, tag_id in zip(sent, tags):\n",
    "                    f.write(f\"{id2word[int(word_id)]} {id2tag[int(tag_id)]}\\n\")\n",
    "                f.write(\"\\n\")\n",
    "\n",
    "report = check(\n",
    "    language=Language,\n",
    "    gold_path=f\"../NER/{Language}/test.txt\",\n",
    "    my_path=output_file,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "73f83993ecc2dce571ce89cddd8a44e114591bb14d9f1f8465ac4f80026585cd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.18 ('AI_A')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
