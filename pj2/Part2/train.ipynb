{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Language = \"English\"\n",
    "Language = \"Chinese\"\n",
    "mode = \"train\"\n",
    "param_num = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-01 16:47:42,165 P79816 INFO train dataset size: 3820\n",
      "2024-06-01 16:47:42,166 P79816 INFO valid dataset size: 462\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "from Part1.dataprocess import data_process, set_log, combine_data\n",
    "from sklearn_crf import sent2features\n",
    "\n",
    "\n",
    "set_log(None)\n",
    "train_data, valid_data, test_data = data_process(f\"../NER/{Language}\", mode=mode)\n",
    "\n",
    "x_train = [sent2features(sentence, Language, param_num) for sentence, _ in train_data]\n",
    "y_train = [label for _, label in train_data]\n",
    "x_valid = [sent2features(sentence, Language, param_num) for sentence, _ in valid_data]\n",
    "y_valid = [label for _, label in valid_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading training data to CRFsuite: 100%|██████████| 3820/3820 [00:01<00:00, 3075.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 1\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 160528\n",
      "Seconds required: 0.504\n",
      "\n",
      "Averaged perceptron\n",
      "max_iterations: 300\n",
      "epsilon: 0.000000\n",
      "\n",
      "Iter 1   time=0.12  loss=445.35   feature_norm=474.25\n",
      "Iter 2   time=0.10  loss=204.26   feature_norm=597.26\n",
      "Iter 3   time=0.10  loss=138.04   feature_norm=673.72\n",
      "Iter 4   time=0.10  loss=104.13   feature_norm=732.69\n",
      "Iter 5   time=0.09  loss=70.30    feature_norm=778.48\n",
      "Iter 6   time=0.10  loss=62.60    feature_norm=815.15\n",
      "Iter 7   time=0.09  loss=46.13    feature_norm=846.00\n",
      "Iter 8   time=0.09  loss=55.17    feature_norm=872.61\n",
      "Iter 9   time=0.09  loss=42.56    feature_norm=897.66\n",
      "Iter 10  time=0.09  loss=24.37    feature_norm=919.90\n",
      "Iter 11  time=0.09  loss=23.68    feature_norm=939.63\n",
      "Iter 12  time=0.09  loss=25.50    feature_norm=957.25\n",
      "Iter 13  time=0.09  loss=14.56    feature_norm=973.35\n",
      "Iter 14  time=0.09  loss=10.83    feature_norm=987.66\n",
      "Iter 15  time=0.09  loss=12.54    feature_norm=1000.71\n",
      "Iter 16  time=0.09  loss=15.26    feature_norm=1012.85\n",
      "Iter 17  time=0.09  loss=8.62     feature_norm=1024.20\n",
      "Iter 18  time=0.09  loss=9.15     feature_norm=1034.61\n",
      "Iter 19  time=0.09  loss=3.72     feature_norm=1044.11\n",
      "Iter 20  time=0.09  loss=10.88    feature_norm=1052.85\n",
      "Iter 21  time=0.09  loss=11.00    feature_norm=1061.01\n",
      "Iter 22  time=0.09  loss=8.95     feature_norm=1068.64\n",
      "Iter 23  time=0.09  loss=2.87     feature_norm=1075.74\n",
      "Iter 24  time=0.09  loss=2.68     feature_norm=1082.32\n",
      "Iter 25  time=0.09  loss=2.52     feature_norm=1088.43\n",
      "Iter 26  time=0.09  loss=3.90     feature_norm=1094.16\n",
      "Iter 27  time=0.09  loss=3.50     feature_norm=1099.55\n",
      "Iter 28  time=0.09  loss=5.82     feature_norm=1104.70\n",
      "Iter 29  time=0.09  loss=9.56     feature_norm=1109.62\n",
      "Iter 30  time=0.09  loss=2.73     feature_norm=1114.32\n",
      "Iter 31  time=0.09  loss=5.93     feature_norm=1118.79\n",
      "Iter 32  time=0.09  loss=6.05     feature_norm=1123.08\n",
      "Iter 33  time=0.09  loss=7.22     feature_norm=1127.22\n",
      "Iter 34  time=0.09  loss=7.88     feature_norm=1131.31\n",
      "Iter 35  time=0.09  loss=5.55     feature_norm=1135.26\n",
      "Iter 36  time=0.09  loss=3.01     feature_norm=1139.08\n",
      "Iter 37  time=0.09  loss=2.93     feature_norm=1142.73\n",
      "Iter 38  time=0.09  loss=1.65     feature_norm=1146.22\n",
      "Iter 39  time=0.09  loss=3.78     feature_norm=1149.56\n",
      "Iter 40  time=0.09  loss=4.74     feature_norm=1152.83\n",
      "Iter 41  time=0.09  loss=2.43     feature_norm=1155.95\n",
      "Iter 42  time=0.09  loss=1.86     feature_norm=1158.96\n",
      "Iter 43  time=0.09  loss=1.21     feature_norm=1161.84\n",
      "Iter 44  time=0.09  loss=2.34     feature_norm=1164.61\n",
      "Iter 45  time=0.09  loss=7.54     feature_norm=1167.38\n",
      "Iter 46  time=0.09  loss=1.12     feature_norm=1170.06\n",
      "Iter 47  time=0.09  loss=0.88     feature_norm=1172.63\n",
      "Iter 48  time=0.09  loss=2.09     feature_norm=1175.11\n",
      "Iter 49  time=0.09  loss=2.02     feature_norm=1177.51\n",
      "Iter 50  time=0.09  loss=1.16     feature_norm=1179.83\n",
      "Iter 51  time=0.09  loss=0.53     feature_norm=1182.06\n",
      "Iter 52  time=0.09  loss=1.61     feature_norm=1184.22\n",
      "Iter 53  time=0.09  loss=1.03     feature_norm=1186.32\n",
      "Iter 54  time=0.09  loss=4.73     feature_norm=1188.35\n",
      "Iter 55  time=0.09  loss=1.00     feature_norm=1190.34\n",
      "Iter 56  time=0.09  loss=1.06     feature_norm=1192.26\n",
      "Iter 57  time=0.09  loss=3.44     feature_norm=1194.13\n",
      "Iter 58  time=0.09  loss=1.84     feature_norm=1195.96\n",
      "Iter 59  time=0.09  loss=1.37     feature_norm=1197.74\n",
      "Iter 60  time=0.09  loss=1.35     feature_norm=1199.47\n",
      "Iter 61  time=0.09  loss=0.66     feature_norm=1201.16\n",
      "Iter 62  time=0.09  loss=1.07     feature_norm=1202.79\n",
      "Iter 63  time=0.09  loss=2.37     feature_norm=1204.38\n",
      "Iter 64  time=0.09  loss=1.44     feature_norm=1205.94\n",
      "Iter 65  time=0.09  loss=1.93     feature_norm=1207.45\n",
      "Iter 66  time=0.09  loss=1.26     feature_norm=1208.93\n",
      "Iter 67  time=0.09  loss=0.66     feature_norm=1210.37\n",
      "Iter 68  time=0.09  loss=4.86     feature_norm=1211.78\n",
      "Iter 69  time=0.09  loss=4.09     feature_norm=1213.18\n",
      "Iter 70  time=0.09  loss=3.42     feature_norm=1214.56\n",
      "Iter 71  time=0.09  loss=4.52     feature_norm=1215.92\n",
      "Iter 72  time=0.09  loss=2.72     feature_norm=1217.26\n",
      "Iter 73  time=0.09  loss=3.97     feature_norm=1218.59\n",
      "Iter 74  time=0.09  loss=2.71     feature_norm=1219.89\n",
      "Iter 75  time=0.09  loss=1.27     feature_norm=1221.17\n",
      "Iter 76  time=0.09  loss=1.94     feature_norm=1222.43\n",
      "Iter 77  time=0.09  loss=1.12     feature_norm=1223.66\n",
      "Iter 78  time=0.09  loss=0.49     feature_norm=1224.86\n",
      "Iter 79  time=0.09  loss=2.31     feature_norm=1226.04\n",
      "Iter 80  time=0.09  loss=0.75     feature_norm=1227.20\n",
      "Iter 81  time=0.09  loss=1.87     feature_norm=1228.33\n",
      "Iter 82  time=0.09  loss=0.72     feature_norm=1229.45\n",
      "Iter 83  time=0.09  loss=3.18     feature_norm=1230.54\n",
      "Iter 84  time=0.09  loss=1.14     feature_norm=1231.62\n",
      "Iter 85  time=0.09  loss=0.48     feature_norm=1232.67\n",
      "Iter 86  time=0.09  loss=1.26     feature_norm=1233.71\n",
      "Iter 87  time=0.09  loss=0.59     feature_norm=1234.72\n",
      "Iter 88  time=0.09  loss=0.53     feature_norm=1235.71\n",
      "Iter 89  time=0.09  loss=0.87     feature_norm=1236.68\n",
      "Iter 90  time=0.09  loss=0.43     feature_norm=1237.64\n",
      "Iter 91  time=0.09  loss=3.46     feature_norm=1238.59\n",
      "Iter 92  time=0.09  loss=1.13     feature_norm=1239.53\n",
      "Iter 93  time=0.09  loss=1.02     feature_norm=1240.46\n",
      "Iter 94  time=0.09  loss=0.38     feature_norm=1241.37\n",
      "Iter 95  time=0.09  loss=0.41     feature_norm=1242.26\n",
      "Iter 96  time=0.09  loss=0.30     feature_norm=1243.14\n",
      "Iter 97  time=0.09  loss=1.07     feature_norm=1243.99\n",
      "Iter 98  time=0.09  loss=0.47     feature_norm=1244.83\n",
      "Iter 99  time=0.09  loss=0.26     feature_norm=1245.66\n",
      "Iter 100 time=0.09  loss=0.53     feature_norm=1246.47\n",
      "Iter 101 time=0.09  loss=0.56     feature_norm=1247.27\n",
      "Iter 102 time=0.09  loss=0.43     feature_norm=1248.05\n",
      "Iter 103 time=0.09  loss=1.10     feature_norm=1248.81\n",
      "Iter 104 time=0.09  loss=2.07     feature_norm=1249.57\n",
      "Iter 105 time=0.09  loss=0.83     feature_norm=1250.32\n",
      "Iter 106 time=0.09  loss=0.63     feature_norm=1251.06\n",
      "Iter 107 time=0.09  loss=1.65     feature_norm=1251.79\n",
      "Iter 108 time=0.09  loss=0.74     feature_norm=1252.50\n",
      "Iter 109 time=0.09  loss=0.68     feature_norm=1253.21\n",
      "Iter 110 time=0.09  loss=1.52     feature_norm=1253.90\n",
      "Iter 111 time=0.09  loss=1.31     feature_norm=1254.59\n",
      "Iter 112 time=0.09  loss=0.32     feature_norm=1255.27\n",
      "Iter 113 time=0.09  loss=0.66     feature_norm=1255.93\n",
      "Iter 114 time=0.09  loss=0.44     feature_norm=1256.59\n",
      "Iter 115 time=0.09  loss=1.02     feature_norm=1257.23\n",
      "Iter 116 time=0.09  loss=2.47     feature_norm=1257.87\n",
      "Iter 117 time=0.09  loss=1.06     feature_norm=1258.50\n",
      "Iter 118 time=0.09  loss=2.90     feature_norm=1259.13\n",
      "Iter 119 time=0.09  loss=3.51     feature_norm=1259.75\n",
      "Iter 120 time=0.09  loss=2.69     feature_norm=1260.38\n",
      "Iter 121 time=0.09  loss=1.80     feature_norm=1261.02\n",
      "Iter 122 time=0.09  loss=1.10     feature_norm=1261.64\n",
      "Iter 123 time=0.09  loss=0.70     feature_norm=1262.26\n",
      "Iter 124 time=0.08  loss=0.69     feature_norm=1262.86\n",
      "Iter 125 time=0.08  loss=0.50     feature_norm=1263.46\n",
      "Iter 126 time=0.09  loss=0.56     feature_norm=1264.05\n",
      "Iter 127 time=0.09  loss=0.73     feature_norm=1264.64\n",
      "Iter 128 time=0.09  loss=0.97     feature_norm=1265.21\n",
      "Iter 129 time=0.09  loss=0.53     feature_norm=1265.78\n",
      "Iter 130 time=0.09  loss=0.57     feature_norm=1266.34\n",
      "Iter 131 time=0.09  loss=1.48     feature_norm=1266.89\n",
      "Iter 132 time=0.08  loss=1.27     feature_norm=1267.44\n",
      "Iter 133 time=0.09  loss=1.83     feature_norm=1267.98\n",
      "Iter 134 time=0.08  loss=0.64     feature_norm=1268.52\n",
      "Iter 135 time=0.09  loss=0.44     feature_norm=1269.05\n",
      "Iter 136 time=0.09  loss=0.47     feature_norm=1269.58\n",
      "Iter 137 time=0.09  loss=0.42     feature_norm=1270.10\n",
      "Iter 138 time=0.08  loss=1.09     feature_norm=1270.61\n",
      "Iter 139 time=0.09  loss=5.98     feature_norm=1271.15\n",
      "Iter 140 time=0.09  loss=1.24     feature_norm=1271.69\n",
      "Iter 141 time=0.09  loss=2.00     feature_norm=1272.24\n",
      "Iter 142 time=0.09  loss=0.63     feature_norm=1272.77\n",
      "Iter 143 time=0.09  loss=3.64     feature_norm=1273.31\n",
      "Iter 144 time=0.09  loss=1.59     feature_norm=1273.85\n",
      "Iter 145 time=0.09  loss=2.13     feature_norm=1274.39\n",
      "Iter 146 time=0.09  loss=0.47     feature_norm=1274.93\n",
      "Iter 147 time=0.09  loss=0.55     feature_norm=1275.45\n",
      "Iter 148 time=0.09  loss=0.82     feature_norm=1275.98\n",
      "Iter 149 time=0.09  loss=3.02     feature_norm=1276.50\n",
      "Iter 150 time=0.09  loss=1.49     feature_norm=1277.03\n",
      "Iter 151 time=0.09  loss=2.59     feature_norm=1277.55\n",
      "Iter 152 time=0.09  loss=1.20     feature_norm=1278.07\n",
      "Iter 153 time=0.09  loss=1.38     feature_norm=1278.58\n",
      "Iter 154 time=0.09  loss=3.29     feature_norm=1279.10\n",
      "Iter 155 time=0.09  loss=2.72     feature_norm=1279.62\n",
      "Iter 156 time=0.08  loss=0.81     feature_norm=1280.13\n",
      "Iter 157 time=0.09  loss=2.23     feature_norm=1280.65\n",
      "Iter 158 time=0.09  loss=1.85     feature_norm=1281.16\n",
      "Iter 159 time=0.09  loss=1.11     feature_norm=1281.66\n",
      "Iter 160 time=0.09  loss=0.57     feature_norm=1282.16\n",
      "Iter 161 time=0.09  loss=3.82     feature_norm=1282.67\n",
      "Iter 162 time=0.09  loss=0.76     feature_norm=1283.18\n",
      "Iter 163 time=0.09  loss=1.35     feature_norm=1283.68\n",
      "Iter 164 time=0.09  loss=2.83     feature_norm=1284.18\n",
      "Iter 165 time=0.09  loss=1.47     feature_norm=1284.68\n",
      "Iter 166 time=0.09  loss=0.49     feature_norm=1285.18\n",
      "Iter 167 time=0.08  loss=0.53     feature_norm=1285.67\n",
      "Iter 168 time=0.09  loss=1.01     feature_norm=1286.16\n",
      "Iter 169 time=0.09  loss=4.61     feature_norm=1286.65\n",
      "Iter 170 time=0.09  loss=1.79     feature_norm=1287.15\n",
      "Iter 171 time=0.09  loss=2.07     feature_norm=1287.64\n",
      "Iter 172 time=0.09  loss=0.77     feature_norm=1288.13\n",
      "Iter 173 time=0.09  loss=1.92     feature_norm=1288.62\n",
      "Iter 174 time=0.09  loss=0.52     feature_norm=1289.10\n",
      "Iter 175 time=0.09  loss=1.41     feature_norm=1289.59\n",
      "Iter 176 time=0.09  loss=1.48     feature_norm=1290.06\n",
      "Iter 177 time=0.09  loss=0.52     feature_norm=1290.54\n",
      "Iter 178 time=0.09  loss=0.77     feature_norm=1291.01\n",
      "Iter 179 time=0.09  loss=0.60     feature_norm=1291.47\n",
      "Iter 180 time=0.09  loss=0.36     feature_norm=1291.93\n",
      "Iter 181 time=0.09  loss=0.38     feature_norm=1292.39\n",
      "Iter 182 time=0.09  loss=1.12     feature_norm=1292.84\n",
      "Iter 183 time=0.09  loss=0.68     feature_norm=1293.29\n",
      "Iter 184 time=0.09  loss=1.18     feature_norm=1293.74\n",
      "Iter 185 time=0.09  loss=0.65     feature_norm=1294.18\n",
      "Iter 186 time=0.09  loss=0.36     feature_norm=1294.61\n",
      "Iter 187 time=0.09  loss=0.42     feature_norm=1295.05\n",
      "Iter 188 time=0.09  loss=0.39     feature_norm=1295.48\n",
      "Iter 189 time=0.09  loss=0.43     feature_norm=1295.90\n",
      "Iter 190 time=0.09  loss=2.45     feature_norm=1296.32\n",
      "Iter 191 time=0.09  loss=3.02     feature_norm=1296.75\n",
      "Iter 192 time=0.09  loss=1.36     feature_norm=1297.18\n",
      "Iter 193 time=0.09  loss=1.56     feature_norm=1297.61\n",
      "Iter 194 time=0.09  loss=0.90     feature_norm=1298.03\n",
      "Iter 195 time=0.09  loss=2.10     feature_norm=1298.45\n",
      "Iter 196 time=0.09  loss=0.44     feature_norm=1298.87\n",
      "Iter 197 time=0.09  loss=0.29     feature_norm=1299.29\n",
      "Iter 198 time=0.09  loss=0.80     feature_norm=1299.70\n",
      "Iter 199 time=0.09  loss=1.62     feature_norm=1300.11\n",
      "Iter 200 time=0.09  loss=1.10     feature_norm=1300.52\n",
      "Iter 201 time=0.09  loss=0.89     feature_norm=1300.92\n",
      "Iter 202 time=0.09  loss=1.17     feature_norm=1301.33\n",
      "Iter 203 time=0.09  loss=0.68     feature_norm=1301.72\n",
      "Iter 204 time=0.09  loss=1.33     feature_norm=1302.12\n",
      "Iter 205 time=0.09  loss=0.87     feature_norm=1302.52\n",
      "Iter 206 time=0.09  loss=0.60     feature_norm=1302.91\n",
      "Iter 207 time=0.09  loss=0.52     feature_norm=1303.30\n",
      "Iter 208 time=0.09  loss=0.44     feature_norm=1303.68\n",
      "Iter 209 time=0.09  loss=0.46     feature_norm=1304.06\n",
      "Iter 210 time=0.09  loss=0.32     feature_norm=1304.44\n",
      "Iter 211 time=0.09  loss=0.52     feature_norm=1304.82\n",
      "Iter 212 time=0.09  loss=1.17     feature_norm=1305.19\n",
      "Iter 213 time=0.09  loss=0.51     feature_norm=1305.56\n",
      "Iter 214 time=0.09  loss=3.17     feature_norm=1305.93\n",
      "Iter 215 time=0.09  loss=0.81     feature_norm=1306.30\n",
      "Iter 216 time=0.09  loss=1.44     feature_norm=1306.66\n",
      "Iter 217 time=0.09  loss=1.88     feature_norm=1307.03\n",
      "Iter 218 time=0.09  loss=1.32     feature_norm=1307.40\n",
      "Iter 219 time=0.09  loss=0.42     feature_norm=1307.76\n",
      "Iter 220 time=0.08  loss=1.19     feature_norm=1308.12\n",
      "Iter 221 time=0.09  loss=0.37     feature_norm=1308.48\n",
      "Iter 222 time=0.09  loss=2.63     feature_norm=1308.84\n",
      "Iter 223 time=0.09  loss=2.37     feature_norm=1309.20\n",
      "Iter 224 time=0.09  loss=0.45     feature_norm=1309.56\n",
      "Iter 225 time=0.09  loss=0.52     feature_norm=1309.91\n",
      "Iter 226 time=0.09  loss=0.45     feature_norm=1310.27\n",
      "Iter 227 time=0.09  loss=0.67     feature_norm=1310.62\n",
      "Iter 228 time=0.09  loss=0.28     feature_norm=1310.96\n",
      "Iter 229 time=0.09  loss=0.42     feature_norm=1311.31\n",
      "Iter 230 time=0.09  loss=0.56     feature_norm=1311.65\n",
      "Iter 231 time=0.09  loss=0.41     feature_norm=1311.99\n",
      "Iter 232 time=0.09  loss=0.56     feature_norm=1312.33\n",
      "Iter 233 time=0.09  loss=0.51     feature_norm=1312.66\n",
      "Iter 234 time=0.09  loss=0.45     feature_norm=1312.99\n",
      "Iter 235 time=0.09  loss=0.42     feature_norm=1313.32\n",
      "Iter 236 time=0.09  loss=0.46     feature_norm=1313.65\n",
      "Iter 237 time=0.09  loss=0.33     feature_norm=1313.97\n",
      "Iter 238 time=0.09  loss=0.58     feature_norm=1314.29\n",
      "Iter 239 time=0.09  loss=0.43     feature_norm=1314.61\n",
      "Iter 240 time=0.09  loss=0.44     feature_norm=1314.93\n",
      "Iter 241 time=0.09  loss=0.59     feature_norm=1315.24\n",
      "Iter 242 time=0.09  loss=0.70     feature_norm=1315.55\n",
      "Iter 243 time=0.09  loss=0.69     feature_norm=1315.86\n",
      "Iter 244 time=0.09  loss=0.55     feature_norm=1316.17\n",
      "Iter 245 time=0.09  loss=0.52     feature_norm=1316.47\n",
      "Iter 246 time=0.09  loss=3.17     feature_norm=1316.78\n",
      "Iter 247 time=0.09  loss=0.63     feature_norm=1317.09\n",
      "Iter 248 time=0.10  loss=0.70     feature_norm=1317.39\n",
      "Iter 249 time=0.09  loss=1.14     feature_norm=1317.69\n",
      "Iter 250 time=0.09  loss=0.42     feature_norm=1318.00\n",
      "Iter 251 time=0.09  loss=0.48     feature_norm=1318.29\n",
      "Iter 252 time=0.09  loss=0.45     feature_norm=1318.59\n",
      "Iter 253 time=0.09  loss=0.47     feature_norm=1318.89\n",
      "Iter 254 time=0.09  loss=0.43     feature_norm=1319.18\n",
      "Iter 255 time=0.09  loss=0.52     feature_norm=1319.47\n",
      "Iter 256 time=0.09  loss=0.44     feature_norm=1319.76\n",
      "Iter 257 time=0.09  loss=0.59     feature_norm=1320.04\n",
      "Iter 258 time=0.09  loss=0.59     feature_norm=1320.33\n",
      "Iter 259 time=0.09  loss=0.47     feature_norm=1320.61\n",
      "Iter 260 time=0.09  loss=0.50     feature_norm=1320.89\n",
      "Iter 261 time=0.09  loss=0.45     feature_norm=1321.17\n",
      "Iter 262 time=0.09  loss=0.48     feature_norm=1321.45\n",
      "Iter 263 time=0.09  loss=0.24     feature_norm=1321.72\n",
      "Iter 264 time=0.09  loss=0.36     feature_norm=1321.99\n",
      "Iter 265 time=0.09  loss=0.28     feature_norm=1322.26\n",
      "Iter 266 time=0.09  loss=0.57     feature_norm=1322.53\n",
      "Iter 267 time=0.09  loss=0.42     feature_norm=1322.80\n",
      "Iter 268 time=0.09  loss=0.47     feature_norm=1323.07\n",
      "Iter 269 time=0.09  loss=0.45     feature_norm=1323.33\n",
      "Iter 270 time=0.09  loss=0.50     feature_norm=1323.59\n",
      "Iter 271 time=0.09  loss=0.49     feature_norm=1323.85\n",
      "Iter 272 time=0.09  loss=0.62     feature_norm=1324.11\n",
      "Iter 273 time=0.09  loss=0.37     feature_norm=1324.36\n",
      "Iter 274 time=0.09  loss=0.50     feature_norm=1324.62\n",
      "Iter 275 time=0.09  loss=0.48     feature_norm=1324.87\n",
      "Iter 276 time=0.08  loss=0.53     feature_norm=1325.12\n",
      "Iter 277 time=0.09  loss=0.47     feature_norm=1325.37\n",
      "Iter 278 time=0.09  loss=0.36     feature_norm=1325.62\n",
      "Iter 279 time=0.09  loss=0.42     feature_norm=1325.86\n",
      "Iter 280 time=0.09  loss=0.35     feature_norm=1326.11\n",
      "Iter 281 time=0.09  loss=0.54     feature_norm=1326.35\n",
      "Iter 282 time=0.09  loss=0.48     feature_norm=1326.59\n",
      "Iter 283 time=0.09  loss=0.88     feature_norm=1326.83\n",
      "Iter 284 time=0.09  loss=0.44     feature_norm=1327.07\n",
      "Iter 285 time=0.09  loss=0.53     feature_norm=1327.31\n",
      "Iter 286 time=0.09  loss=0.28     feature_norm=1327.54\n",
      "Iter 287 time=0.09  loss=0.48     feature_norm=1327.77\n",
      "Iter 288 time=0.09  loss=0.34     feature_norm=1328.01\n",
      "Iter 289 time=0.09  loss=0.49     feature_norm=1328.24\n",
      "Iter 290 time=0.09  loss=0.47     feature_norm=1328.46\n",
      "Iter 291 time=0.09  loss=0.42     feature_norm=1328.69\n",
      "Iter 292 time=0.09  loss=0.37     feature_norm=1328.92\n",
      "Iter 293 time=0.09  loss=0.46     feature_norm=1329.14\n",
      "Iter 294 time=0.09  loss=0.48     feature_norm=1329.36\n",
      "Iter 295 time=0.09  loss=0.52     feature_norm=1329.59\n",
      "Iter 296 time=0.09  loss=0.43     feature_norm=1329.81\n",
      "Iter 297 time=0.09  loss=0.47     feature_norm=1330.02\n",
      "Iter 298 time=0.09  loss=0.62     feature_norm=1330.24\n",
      "Iter 299 time=0.09  loss=0.53     feature_norm=1330.46\n",
      "Iter 300 time=0.09  loss=0.44     feature_norm=1330.67\n",
      "Total seconds required for training: 26.684\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 96325 (160528)\n",
      "Number of active attributes: 74665 (135249)\n",
      "Number of active labels: 28 (28)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn_crfsuite import CRF\n",
    "\n",
    "if param_num == 0:\n",
    "    crf_model = CRF(\n",
    "        algorithm=\"lbfgs\",\n",
    "        c1=0.01,\n",
    "        c2=0.01,\n",
    "        max_iterations=200,\n",
    "        all_possible_transitions=True,\n",
    "        verbose=True,\n",
    "    )\n",
    "elif param_num == 1:\n",
    "    crf_model = CRF(\n",
    "        algorithm=\"ap\",\n",
    "        max_iterations=300,\n",
    "        all_possible_transitions=True,\n",
    "        verbose=True,\n",
    "    )\n",
    "elif param_num == 2:\n",
    "    raise NotImplementedError\n",
    "\n",
    "crf_model.fit(x_train, y_train)\n",
    "with open(f\"crf_{Language}{param_num}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(crf_model, f)\n",
    "\n",
    "y_pred = crf_model.predict(x_valid)\n",
    "combined_data = combine_data([sentence for sentence, _ in valid_data], y_pred)\n",
    "\n",
    "output_file = f\"output_{Language}.txt\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(combined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      B-NAME     0.9806    0.9902    0.9854       102\n",
      "      M-NAME     0.9867    0.9867    0.9867        75\n",
      "      E-NAME     0.9806    0.9902    0.9854       102\n",
      "      S-NAME     1.0000    1.0000    1.0000         8\n",
      "      B-CONT     1.0000    1.0000    1.0000        33\n",
      "      M-CONT     1.0000    1.0000    1.0000        64\n",
      "      E-CONT     1.0000    1.0000    1.0000        33\n",
      "      S-CONT     0.0000    0.0000    0.0000         0\n",
      "       B-EDU     0.9722    0.9906    0.9813       106\n",
      "       M-EDU     0.9620    1.0000    0.9806       177\n",
      "       E-EDU     0.9541    0.9811    0.9674       106\n",
      "       S-EDU     0.0000    0.0000    0.0000         0\n",
      "     B-TITLE     0.9187    0.9187    0.9187       689\n",
      "     M-TITLE     0.9050    0.9270    0.9158      1479\n",
      "     E-TITLE     0.9841    0.9855    0.9848       689\n",
      "     S-TITLE     0.0000    0.0000    0.0000         0\n",
      "       B-ORG     0.9484    0.9502    0.9493       522\n",
      "       M-ORG     0.9375    0.9564    0.9468      3622\n",
      "       E-ORG     0.8969    0.9004    0.8987       522\n",
      "       S-ORG     0.0000    0.0000    0.0000         0\n",
      "      B-RACE     1.0000    1.0000    1.0000        14\n",
      "      M-RACE     0.0000    0.0000    0.0000         0\n",
      "      E-RACE     1.0000    1.0000    1.0000        14\n",
      "      S-RACE     0.0000    0.0000    0.0000         1\n",
      "       B-PRO     0.8500    0.9444    0.8947        18\n",
      "       M-PRO     0.7857    1.0000    0.8800        33\n",
      "       E-PRO     0.8571    1.0000    0.9231        18\n",
      "       S-PRO     0.0000    0.0000    0.0000         0\n",
      "       B-LOC     1.0000    1.0000    1.0000         2\n",
      "       M-LOC     1.0000    1.0000    1.0000         6\n",
      "       E-LOC     1.0000    1.0000    1.0000         2\n",
      "       S-LOC     0.0000    0.0000    0.0000         0\n",
      "\n",
      "   micro avg     0.9349    0.9505    0.9426      8437\n",
      "   macro avg     0.7162    0.7350    0.7250      8437\n",
      "weighted avg     0.9351    0.9505    0.9426      8437\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from NER.check import check\n",
    "\n",
    "report = check(\n",
    "    language=Language,\n",
    "    gold_path=f\"../NER/{Language}/validation.txt\",\n",
    "    my_path=output_file,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
