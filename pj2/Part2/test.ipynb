{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Language = \"English\"\n",
    "Language = \"Chinese\"\n",
    "mode = \"test\"\n",
    "param_num = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-08 23:03:52,881 P35768 INFO test dataset size: 476\n",
      "2024-06-08 23:03:52,881 P35768 INFO train dataset size: 3820\n",
      "2024-06-08 23:03:52,882 P35768 INFO valid dataset size: 462\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "from Part1.dataprocess import data_process, set_log, combine_data\n",
    "from sklearn_crf import sent2features\n",
    "\n",
    "\n",
    "set_log(None)\n",
    "train_data, valid_data, test_data = data_process(f\"../NER/{Language}\", mode=mode)\n",
    "\n",
    "x_test = [sent2features(sentence, Language, param_num) for sentence, _ in test_data]\n",
    "y_test = [label for _, label in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn_crfsuite import CRF\n",
    "\n",
    "with open(f\"crf_{Language}{param_num}.pkl\", \"rb\") as f:\n",
    "    crf_model = pickle.load(f)\n",
    "\n",
    "y_pred = crf_model.predict(x_test)\n",
    "combined_data = combine_data([sentence for sentence, _ in test_data], y_pred)\n",
    "\n",
    "output_file = f\"output_{Language}.txt\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(combined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      B-NAME     0.9910    0.9821    0.9865       112\n",
      "      M-NAME     1.0000    0.9634    0.9814        82\n",
      "      E-NAME     1.0000    0.9821    0.9910       112\n",
      "      S-NAME     0.0000    0.0000    0.0000         0\n",
      "      B-CONT     1.0000    1.0000    1.0000        28\n",
      "      M-CONT     1.0000    1.0000    1.0000        53\n",
      "      E-CONT     1.0000    1.0000    1.0000        28\n",
      "      S-CONT     0.0000    0.0000    0.0000         0\n",
      "       B-EDU     0.9646    0.9732    0.9689       112\n",
      "       M-EDU     0.9714    0.9497    0.9605       179\n",
      "       E-EDU     0.9735    0.9821    0.9778       112\n",
      "       S-EDU     0.0000    0.0000    0.0000         0\n",
      "     B-TITLE     0.9342    0.9403    0.9372       770\n",
      "     M-TITLE     0.9503    0.9053    0.9272      1921\n",
      "     E-TITLE     0.9781    0.9870    0.9825       770\n",
      "     S-TITLE     0.0000    0.0000    0.0000         0\n",
      "       B-ORG     0.9417    0.9656    0.9535       552\n",
      "       M-ORG     0.9452    0.9675    0.9562      4312\n",
      "       E-ORG     0.9007    0.9203    0.9104       552\n",
      "       S-ORG     0.0000    0.0000    0.0000         0\n",
      "      B-RACE     1.0000    1.0000    1.0000        14\n",
      "      M-RACE     0.0000    0.0000    0.0000         0\n",
      "      E-RACE     1.0000    1.0000    1.0000        14\n",
      "      S-RACE     0.0000    0.0000    0.0000         0\n",
      "       B-PRO     0.9091    0.9091    0.9091        33\n",
      "       M-PRO     0.7831    0.9559    0.8609        68\n",
      "       E-PRO     0.8857    0.9394    0.9118        33\n",
      "       S-PRO     0.0000    0.0000    0.0000         0\n",
      "       B-LOC     1.0000    1.0000    1.0000         6\n",
      "       M-LOC     1.0000    1.0000    1.0000        21\n",
      "       E-LOC     1.0000    1.0000    1.0000         6\n",
      "       S-LOC     0.0000    0.0000    0.0000         0\n",
      "\n",
      "   micro avg     0.9469    0.9525    0.9497      9890\n",
      "   macro avg     0.6915    0.6976    0.6942      9890\n",
      "weighted avg     0.9473    0.9525    0.9496      9890\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from NER.check import check\n",
    "\n",
    "report = check(\n",
    "    language=Language,\n",
    "    gold_path=f\"../NER/{Language}/test.txt\",\n",
    "    my_path=output_file,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "73f83993ecc2dce571ce89cddd8a44e114591bb14d9f1f8465ac4f80026585cd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.18 ('AI_A')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
