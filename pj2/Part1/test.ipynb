{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Language = \"English\"\n",
    "Language = \"Chinese\"\n",
    "mode = \"test\"\n",
    "param_num = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-12 13:41:43,948 P99864 INFO test dataset size: 476\n",
      "2024-06-12 13:41:43,951 P99864 INFO train dataset size: 3820\n",
      "2024-06-12 13:41:43,951 P99864 INFO valid dataset size: 462\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m HMMModel(tag2idx, vocab)\n\u001b[1;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39mload_param(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mLanguage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mparam_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnpz\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m combined_data \u001b[38;5;241m=\u001b[39m combine_data([sentence \u001b[38;5;28;01mfor\u001b[39;00m sentence, _ \u001b[38;5;129;01min\u001b[39;00m test_data], y_pred)\n\u001b[1;32m     18\u001b[0m output_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mLanguage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Downloads/AI_A-main/Project2/Part1/HMM.py:72\u001b[0m, in \u001b[0;36mHMMModel.valid\u001b[0;34m(self, valid_data)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalid\u001b[39m(\u001b[38;5;28mself\u001b[39m, valid_data):\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mviterbi(sentence) \u001b[38;5;28;01mfor\u001b[39;00m sentence, _ \u001b[38;5;129;01min\u001b[39;00m valid_data]\n",
      "File \u001b[0;32m~/Downloads/AI_A-main/Project2/Part1/HMM.py:72\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalid\u001b[39m(\u001b[38;5;28mself\u001b[39m, valid_data):\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mviterbi\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m sentence, _ \u001b[38;5;129;01min\u001b[39;00m valid_data]\n",
      "File \u001b[0;32m~/Downloads/AI_A-main/Project2/Part1/HMM.py:69\u001b[0m, in \u001b[0;36mHMMModel.viterbi\u001b[0;34m(self, O)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(T \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     67\u001b[0m     best_path[t] \u001b[38;5;241m=\u001b[39m psi[best_path[t \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m], t \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midx2tag[\u001b[38;5;28mid\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mid\u001b[39m \u001b[38;5;129;01min\u001b[39;00m best_path]\n",
      "File \u001b[0;32m~/Downloads/AI_A-main/Project2/Part1/HMM.py:69\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(T \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     67\u001b[0m     best_path[t] \u001b[38;5;241m=\u001b[39m psi[best_path[t \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m], t \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43midx2tag\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mid\u001b[39m \u001b[38;5;129;01min\u001b[39;00m best_path]\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "from Part1.data_process import build_vocab, build_tag2idx, data_process, set_log, combine_data\n",
    "from Part1.HMM_model import HMMModel\n",
    "\n",
    "\n",
    "set_log(None)\n",
    "tag2idx = build_tag2idx(f\"../NER/{Language}/tag.txt\")\n",
    "train_data, valid_data, test_data = data_process(f\"../NER/{Language}\", mode=mode)\n",
    "\n",
    "train_path = f\"../NER/{Language}/train.txt\"\n",
    "vocab = build_vocab([train_path])\n",
    "\n",
    "model = HMMModel(tag2idx, vocab)\n",
    "model.load_param(f\"{Language}{param_num}\", format=\"npz\")\n",
    "\n",
    "y_pred = model.valid(test_data)\n",
    "combined_data = combine_data([sentence for sentence, _ in test_data], y_pred)\n",
    "\n",
    "output_file = f\"output_{Language}.txt\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(combined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      B-NAME     0.9800    0.8750    0.9245       112\n",
      "      M-NAME     0.9459    0.8537    0.8974        82\n",
      "      E-NAME     0.9000    0.8036    0.8491       112\n",
      "      S-NAME     0.0000    0.0000    0.0000         0\n",
      "      B-CONT     0.9655    1.0000    0.9825        28\n",
      "      M-CONT     0.9815    1.0000    0.9907        53\n",
      "      E-CONT     0.9655    1.0000    0.9825        28\n",
      "      S-CONT     0.0000    0.0000    0.0000         0\n",
      "       B-EDU     0.9000    0.9643    0.9310       112\n",
      "       M-EDU     0.9348    0.9609    0.9477       179\n",
      "       E-EDU     0.9167    0.9821    0.9483       112\n",
      "       S-EDU     0.0000    0.0000    0.0000         0\n",
      "     B-TITLE     0.8784    0.8909    0.8846       770\n",
      "     M-TITLE     0.9006    0.8725    0.8863      1921\n",
      "     E-TITLE     0.9501    0.9636    0.9568       770\n",
      "     S-TITLE     0.0000    0.0000    0.0000         0\n",
      "       B-ORG     0.8351    0.8804    0.8571       552\n",
      "       M-ORG     0.9015    0.9316    0.9163      4312\n",
      "       E-ORG     0.8241    0.8659    0.8445       552\n",
      "       S-ORG     0.0000    0.0000    0.0000         0\n",
      "      B-RACE     1.0000    0.9286    0.9630        14\n",
      "      M-RACE     0.0000    0.0000    0.0000         0\n",
      "      E-RACE     1.0000    0.9286    0.9630        14\n",
      "      S-RACE     0.0000    0.0000    0.0000         0\n",
      "       B-PRO     0.5581    0.7273    0.6316        33\n",
      "       M-PRO     0.4479    0.6324    0.5244        68\n",
      "       E-PRO     0.6512    0.8485    0.7368        33\n",
      "       S-PRO     0.0000    0.0000    0.0000         0\n",
      "       B-LOC     0.3333    0.3333    0.3333         6\n",
      "       M-LOC     0.5833    0.3333    0.4242        21\n",
      "       E-LOC     0.5000    0.5000    0.5000         6\n",
      "       S-LOC     0.0000    0.0000    0.0000         0\n",
      "\n",
      "   micro avg     0.8896    0.9075    0.8984      9890\n",
      "   macro avg     0.5892    0.5961    0.5899      9890\n",
      "weighted avg     0.8920    0.9075    0.8991      9890\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "from NER.check import check\n",
    "\n",
    "report = check(\n",
    "    language=Language,\n",
    "    gold_path=f\"../NER/{Language}/test.txt\",\n",
    "    my_path=output_file,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "73f83993ecc2dce571ce89cddd8a44e114591bb14d9f1f8465ac4f80026585cd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.18 ('AI_A')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
